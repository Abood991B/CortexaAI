# API Keys - Required for LLM providers
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# LangSmith Configuration - Optional for tracing
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=prompt-engineering-system
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# Model Configuration
DEFAULT_MODEL_PROVIDER=google
DEFAULT_MODEL_NAME=gemini-2.0-flash

# System Configuration
LOG_LEVEL=INFO
MAX_EVALUATION_ITERATIONS=3
EVALUATION_THRESHOLD=0.8

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Performance Configuration
ENABLE_CACHING=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000
ENABLE_PERFORMANCE_TRACKING=true

# Security Configuration
SECURITY_LEVEL=balanced
ENABLE_INPUT_SANITIZATION=true
ENABLE_CONTENT_FILTERING=true
ENABLE_PII_DETECTION=true

# Circuit Breaker Configuration
ENABLE_CIRCUIT_BREAKERS=true
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=60

# Dead Letter Queue Configuration
ENABLE_DLQ=true
DLQ_MAX_SIZE=1000
DLQ_RETENTION_HOURS=24

# Memory Configuration
ENABLE_RAG=false
RAG_TOP_K=5
MEMORY_CACHE_SIZE=100
