# ============================================================
# CortexaAI - Environment Configuration
# ============================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# At minimum, you need ONE LLM provider API key.
# Google Gemini is recommended (free tier available).
# ============================================================

# ============================================================
# LLM Provider API Keys (at least one required)
# ============================================================

# Google AI - Gemini & Gemma (free tier at aistudio.google.com)
GOOGLE_API_KEY=

# OpenAI - GPT-4, GPT-3.5 (optional)
OPENAI_API_KEY=

# Anthropic - Claude (optional)
ANTHROPIC_API_KEY=

# Groq - Ultra-fast inference, free tier (console.groq.com)
GROQ_API_KEY=

# DeepSeek - Powerful reasoning (platform.deepseek.com)
DEEPSEEK_API_KEY=

# OpenRouter - 100+ models, some free (openrouter.ai)
OPENROUTER_API_KEY=

# ============================================================
# Default LLM Model Selection
# ============================================================
# Provider: google | openai | anthropic | groq | deepseek | openrouter
DEFAULT_MODEL_PROVIDER=google

# Model name (must match the provider above)
#   google:     gemini-2.0-flash, gemini-2.5-flash-lite, gemma-3-27b-it, gemma-3-12b-it, gemma-3-4b-it
#   openai:     gpt-4o-mini, gpt-4o, gpt-4-turbo
#   anthropic:  claude-3-haiku-20240307, claude-3-sonnet-20240229
#   groq:       llama-3.3-70b-versatile, mixtral-8x7b-32768, gemma2-9b-it
#   deepseek:   deepseek-chat, deepseek-reasoner
#   openrouter: google/gemini-2.0-flash-exp:free, meta-llama/llama-3.3-70b-instruct:free
DEFAULT_MODEL_NAME=gemini-2.0-flash

# ============================================================
# LangSmith Monitoring (Optional - for workflow tracing)
# ============================================================
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=Prompt-Engineer-Agent
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# ============================================================
# System Configuration
# ============================================================
LOG_LEVEL=INFO
MAX_EVALUATION_ITERATIONS=5
EVALUATION_THRESHOLD=0.8

# ============================================================
# Server Configuration
# ============================================================
HOST=0.0.0.0
PORT=8000

# ----------------------------------------------------------
# Memory / RAG (experimental)
# ----------------------------------------------------------
ENABLE_RAG=false
RAG_TOP_K=5
MEMORY_CACHE_SIZE=100
